{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction intervals\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/etna-team/etna/master?filepath=examples/306-prediction_intervals.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains overview of prediction intervals functionality in ETNA library.\n",
    "\n",
    "**Table of contents**\n",
    "\n",
    "* [Loading and preparing data](#chapter1)\n",
    "* [Estimating intervals using builtin method](#chapter2)\n",
    "    * [Accessing prediction intervals in `TSDataset`](#chapter2_1)\n",
    "    * [Computing interval metrics](#chapter2_2)\n",
    "* [Estimating prediction intervals using `experimental.prediction_intervals` module](#chapter3)\n",
    "    * [`NaiveVariancePredictionIntervals`](#chapter3_1)\n",
    "    * [`ConformalPredictionIntervals`](#chapter3_2)\n",
    "    * [`EmpiricalPredictionIntervals`](#chapter3_3)\n",
    "* [Custom prediction interval method](#chapter4)\n",
    "    * [Non-parametric method](#chapter4_1)\n",
    "    * [Estimating historical residuals](#chapter4_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from etna.analysis.forecast import plot_forecast\n",
    "from etna.datasets import TSDataset\n",
    "from etna.metrics import Coverage\n",
    "from etna.metrics import Width\n",
    "from etna.models import CatBoostMultiSegmentModel\n",
    "from etna.pipeline import Pipeline\n",
    "from etna.transforms import DateFlagsTransform\n",
    "from etna.transforms import LagTransform\n",
    "from etna.transforms import LinearTrendTransform\n",
    "from etna.transforms import LogTransform\n",
    "from etna.transforms import MeanTransform\n",
    "from etna.transforms import SegmentEncoderTransform\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing data <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "\n",
    "\n",
    "Consider the dataset `data/example_dataset.csv`.\n",
    "\n",
    "This data will be used to show how prediction intervals could be estimated and accessed in ETNA library.\n",
    "\n",
    "First step is to load data and convert it to the `TSDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/example_dataset.csv\")\n",
    "df = TSDataset.to_dataset(df=df)\n",
    "ts = TSDataset(df=df, freq=\"D\")\n",
    "\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have four segments in the dataset. All segments have seasonalities, and some of them show signs of trend.\n",
    "Note that segment C contains obvious outlier, that may affect quality of estimated intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the next step we split our dataset into two parts: train and test. Test part will be used as a hold out dataset for metrics\n",
    "computation and result analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ts, test_ts = ts.train_test_split(test_size=HORIZON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating intervals using builtin method <a class=\"anchor\" id=\"chapter2\"></a>\n",
    "\n",
    "Currently there are several types of prediction intervals in the library:\n",
    "1. Quantiles estimates\n",
    "2. Arbitrary interval borders, that tends to provide desired coverage\n",
    "\n",
    "Methods, implemented in the library, use univariate distribution to estimate quantiles at each timestamp in the horizon. There is possibility to treat all timestamps in the horizon jointly\n",
    "and threat horizon as multivariate random variable to estimate quatiles. Extension of current method pool will be discussed in the last section of this notebook.\n",
    "\n",
    "So there are some naming convention to achieve distinction between two types of intervals. Borders that approximate quantiles named in the following format `{target_{q:.4g}}`, where `q`\n",
    "is corresponding quantile level. And there no particular rules for the arbitrary borders. But it is implementation responsibility to name them appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before estimating prediction intervals we need to fit a model. Here `CatBoostMultiSegmentModel` is used with lag and date features.\n",
    "This model requires computed features, so we add corresponding transforms to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogTransform(in_column=\"target\")\n",
    "trend = LinearTrendTransform(in_column=\"target\")\n",
    "seg = SegmentEncoderTransform()\n",
    "lags = LagTransform(in_column=\"target\", lags=list(range(HORIZON, 20 + HORIZON)), out_column=\"lag\")\n",
    "date_flags = DateFlagsTransform(\n",
    "    day_number_in_week=True,\n",
    "    day_number_in_month=True,\n",
    "    week_number_in_month=True,\n",
    "    week_number_in_year=True,\n",
    "    month_number_in_year=True,\n",
    "    year_number=True,\n",
    "    is_weekend=True,\n",
    ")\n",
    "mean = MeanTransform(in_column=f\"lag_{HORIZON}\", window=30)\n",
    "\n",
    "transforms = [\n",
    "    # log,\n",
    "    # trend,\n",
    "    lags,\n",
    "    date_flags,\n",
    "    seg,\n",
    "    # mean\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostMultiSegmentModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(model=model, transforms=transforms, horizon=HORIZON)\n",
    "\n",
    "pipeline.fit(ts=train_ts);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After pipeline is defined and fitted we are able to estimate prediction intervals with the default method. To do so\n",
    "set `prediction_interval=True` parameter of `forecast` method.\n",
    "\n",
    "This prediction intervals method is based on residual variance estimation and $z$-scores. Variance estimation is done via running\n",
    "historical backtest on non-overlapping folds. Number of folds controlled via `n_folds` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = pipeline.forecast(ts=train_ts, prediction_interval=True, n_folds=7)\n",
    "forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have point forecast for full horizon alongside with estimated prediction interval for each segment.\n",
    "\n",
    "Section below describes how one can perform manipulations with intervals in the dataset of forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing prediction intervals in `TSDataset` <a class=\"anchor\" id=\"chapter2_1\"></a>\n",
    "\n",
    "Column names for the estimated prediction intervals can be obtained using `TSDataset.prediction_intervals_names` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.prediction_intervals_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here segment names are omitted, because they share interval estimation method. So column names identical for all the segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe with prediction intervals only for each segment can be obtained by using `TSDataset.get_prediction_intervals()` method.\n",
    "\n",
    "Here we save such dataframe to the separate object to use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_intervals = forecast.get_prediction_intervals()\n",
    "prediction_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If estimated intervals are no longer needed or there is a necessity to remove prediction intervals from the dataset use\n",
    "`TSDataset.drop_prediction_intervals()` method.\n",
    "\n",
    "Once we removed intervals, we can check that they are no longer presented by looking at stored names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.drop_prediction_intervals()\n",
    "forecast.prediction_intervals_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that property contains empty tuple now. It is indication that no intervals are registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.get_prediction_intervals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `TSDataset.get_prediction_intervals()` in such case will return `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a possibility to add existing prediction intervals to the dataset. To do so one should use\n",
    " `TSDataset.add_prediction_intervals()` method.\n",
    "\n",
    "There are a couple requirements when adding existing intervals to the dataset.\n",
    "1. There are should be no intervals in the dataset. This could be checked via `prediction_intervals_names` property.\n",
    "2. Dataframe with intervals should be in ETNA wide format.\n",
    "3. All segments should be matched between dataset and intervals dataframe\n",
    "4. Interval borders sets should match for all the segments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.add_prediction_intervals(prediction_intervals_df=prediction_intervals)\n",
    "forecast.prediction_intervals_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we called `prediction_intervals_names` to make sure that intervals added correctly and printed out resulting dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results visualisation could be done using `plot_forecast` function. Setting parameter `prediction_intervals=True` will\n",
    "enable plotting estimated prediction intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(forecast, test_ts, train_ts, prediction_intervals=True, n_train_samples=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing interval metrics <a class=\"anchor\" id=\"chapter2_2\"></a>\n",
    "\n",
    "There are a couple of metrics in the library that can help to estimate quality if computed prediction intervals:\n",
    "* `Coverage` - percentage of points in the horizon covered by the interval\n",
    "* `Width` - mean width of the prediction interval on full horizon.\n",
    "\n",
    "This metrics require initialization. To specify which interval to use provide border names by setting\n",
    "`lower_name` and `upper_name` parameters. After initialization this metrics will try to find specified borders in\n",
    " the dataset with predicted values. If provided names not found corresponding error will be raised.\n",
    "\n",
    "Here we wrap metrics estimation in one function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_metrics(test_ts, forecast):\n",
    "    lower_name, upper_name = forecast.prediction_intervals_names\n",
    "\n",
    "    coverage = Coverage(lower_name=lower_name, upper_name=upper_name)(test_ts, forecast)\n",
    "    width = Width(lower_name=lower_name, upper_name=upper_name)(test_ts, forecast)\n",
    "\n",
    "    return coverage, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage, width = interval_metrics(test_ts=test_ts, forecast=forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating prediction intervals using `experimental.prediction_intervals` module <a class=\"anchor\" id=\"chapter3\"></a>\n",
    "\n",
    "ETNA library provides several alternative methods for prediction intervals estimation. All necessary functionality is at\n",
    "`etna.experimental.prediction_intervals` module.\n",
    "\n",
    "This section covers currently implemented methods. Also module provides possibility to easily extend methods list\n",
    "by implementing custom one. This topic will be discussed in the next section.\n",
    "\n",
    "Prediction intervals functionality is implemented via wrapper classes for the ETNA pipelines. While initialization such\n",
    "methods require pipeline instance and necessary hyperparameters. Provided pipeline can be fitted before or after wrapping\n",
    "with the intervals estimation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `NaiveVariancePredictionIntervals` <a class=\"anchor\" id=\"chapter3_1\"></a>\n",
    "This method estimate prediction quantiles using the following algorithm:\n",
    "\n",
    "1. Compute the residuals matrix $r_{it} = \\hat y_{it} - y_{it}$ using k-fold backtest, where $i$ is fold index.\n",
    "\n",
    "2. Estimate variance for each step in the prediction horizon $v_t = \\frac{1}{k} \\sum_{i = 1}^k r_{it}^2$.\n",
    "\n",
    "3. Use $z$-scores and estimated variance to compute corresponding quantiles.\n",
    "\n",
    "\n",
    "Desired quantiles levels for the prediction interval can be set via `quantiles` of the `forecast` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etna.experimental.prediction_intervals import NaiveVariancePredictionIntervals\n",
    "\n",
    "pipeline = NaiveVariancePredictionIntervals(pipeline=pipeline)\n",
    "\n",
    "forecast = pipeline.forecast(quantiles=(0.025, 0.975), prediction_interval=True, n_folds=40)\n",
    "\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(forecast, test_ts, train_ts, prediction_intervals=True, n_train_samples=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage, width = interval_metrics(test_ts=test_ts, forecast=forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ConformalPredictionIntervals` <a class=\"anchor\" id=\"chapter3_2\"></a>\n",
    "\n",
    "Estimates conformal prediction intervals:\n",
    "\n",
    "1. Compute matrix of absolute residuals  $r_{it} = |\\hat y_{it} - y_{it}|$ using k-fold historical backtest, where $i$ is fold index.\n",
    "\n",
    "2. Estimate corresponding quantiles levels using the provided coverage (e.g. apply Bonferroni correction).\n",
    "\n",
    "3. Estimate quantiles for each horizon step separately using computed absolute residuals and levels.\n",
    "\n",
    "\n",
    "**Note**: this method estimates arbitrary interval bounds that tends to provide given coverage rate.\n",
    "So this method ignores `quantiles` parameter of `forecast` method.\n",
    "\n",
    "Coverage rate and correction option should be set at method initialization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etna.experimental.prediction_intervals import ConformalPredictionIntervals\n",
    "\n",
    "pipeline = ConformalPredictionIntervals(pipeline=pipeline, coverage=0.95, bonferroni_correction=True)\n",
    "\n",
    "forecast = pipeline.forecast(prediction_interval=True, n_folds=40)\n",
    "\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(forecast, test_ts, train_ts, prediction_intervals=True, n_train_samples=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage, width = interval_metrics(test_ts=test_ts, forecast=forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `EmpiricalPredictionIntervals` <a class=\"anchor\" id=\"chapter3_3\"></a>\n",
    "\n",
    "Estimates prediction intervals via historical residuals:\n",
    "\n",
    "1. Compute matrix of residuals  $r_{it} = |\\hat y_{it} - y_{it}|$ using k-fold backtest, where $i$ is fold index.\n",
    "\n",
    "2. Estimate quantiles levels, that satisfy the provided coverage, for the corresponding residuals distributions.\n",
    "\n",
    "3. Estimate quantiles for each timestamp using computed residuals and levels.\n",
    "\n",
    "\n",
    "**Note**: this method estimates arbitrary interval bounds that tends to provide given coverage rate.\n",
    "So this method ignores `quantiles` parameter of `forecast` method.\n",
    "\n",
    "Coverage rate and correction option should be set at method initialization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etna.experimental.prediction_intervals import EmpiricalPredictionIntervals\n",
    "\n",
    "pipeline = EmpiricalPredictionIntervals(pipeline=pipeline)\n",
    "\n",
    "forecast = pipeline.forecast(prediction_interval=True, n_folds=40)\n",
    "\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(forecast, test_ts, train_ts, prediction_intervals=True, n_train_samples=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage, width = interval_metrics(test_ts=test_ts, forecast=forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom prediction interval method <a class=\"anchor\" id=\"chapter4\"></a>\n",
    "\n",
    "There is a possibility in the library to extend set of prediction intervals methods by implementing desired algorithm.\n",
    "This section demonstrates may how it can be done. Examples of interface and utilities usage provided as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BasePredictionIntervals` - base class for prediction intervals methods.\n",
    "\n",
    "This class implements a wrapper interface for pipelines and ensembles that provides the ability to\n",
    "estimate prediction intervals. So it requires a pipeline instance to be provided to `__init__` method to do proper initialization.\n",
    "\n",
    "To add a particular method for pipelines, one must inherit from this class and provide an implementation for the\n",
    "abstract method ``_forecast_prediction_interval``. This method should estimate and store prediction\n",
    "intervals for out-of-sample forecasts.\n",
    "\n",
    "**Limitations**\n",
    "In-sample prediction is not supported by default and will raise a corresponding error while attempting to do so.\n",
    "This functionality could be implemented if needed by overriding ``_predict`` method, which is responsible\n",
    "for building an in-sample point forecast and adding prediction intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-parametric method <a class=\"anchor\" id=\"chapter4_1\"></a>\n",
    "\n",
    "Example below demonstrates how interval method could be implemented.\n",
    "\n",
    "Consider `ConstantWidthInterval` which simply adds constant `width` to point forecast. Here `width` is hyperparameter\n",
    "that will be set on method initialization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from etna.experimental.prediction_intervals import BasePredictionIntervals\n",
    "from etna.pipeline import BasePipeline\n",
    "\n",
    "\n",
    "class ConstantWidthInterval(BasePredictionIntervals):\n",
    "    def __init__(self, pipeline: BasePipeline, interval_width: float):\n",
    "        assert interval_width > 0\n",
    "\n",
    "        self.interval_width = interval_width\n",
    "        super().__init__(pipeline=pipeline)\n",
    "\n",
    "    def _forecast_prediction_interval(\n",
    "        self, ts: TSDataset, predictions: TSDataset, quantiles: Sequence[float], n_folds: int\n",
    "    ) -> TSDataset:\n",
    "        predicted_target = predictions[..., \"target\"]\n",
    "\n",
    "        lower_border = predicted_target - self.interval_width / 2\n",
    "        upper_border = predicted_target + self.interval_width / 2\n",
    "\n",
    "        upper_border.rename({\"target\": \"target_upper\"}, inplace=True, axis=1)\n",
    "        lower_border.rename({\"target\": \"target_lower\"}, inplace=True, axis=1)\n",
    "\n",
    "        predictions.add_prediction_intervals(prediction_intervals_df=pd.concat([lower_border, upper_border], axis=1))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ConstantWidthInterval(pipeline=pipeline, interval_width=150)\n",
    "\n",
    "forecast = pipeline.forecast(prediction_interval=True, n_folds=40)\n",
    "\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(forecast, test_ts, train_ts, prediction_intervals=True, n_train_samples=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage, width = interval_metrics(test_ts=test_ts, forecast=forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating historical residuals <a class=\"anchor\" id=\"chapter4_2\"></a>\n",
    "\n",
    "Some prediction intervals methods require doing forecast on historical data. This could be done by\n",
    "using pipelines `get_historical_forecasts` method. As `BasePredictionIntervals` wraps pipelines this method implemented here as well.\n",
    "\n",
    "Consider `MaxAbsResidInterval` example method. It estimates intervals based on maximum absolute values of historical\n",
    "residuals for each segment. So we can brake down this algorithm into following steps:\n",
    "1. Estimate historical forecast by calling `get_historical_forecasts` method\n",
    "2. For each `segment` estimate residuals, find maximum absolute value and add to point forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxAbsResidInterval(BasePredictionIntervals):\n",
    "    def __init__(self, pipeline: BasePipeline, coverage: float = 0.95, stride: int = 1):\n",
    "        assert stride > 0\n",
    "        assert 0 < coverage <= 1\n",
    "\n",
    "        self.stride = stride\n",
    "        self.coverage = coverage\n",
    "        super().__init__(pipeline=pipeline)\n",
    "\n",
    "    def _forecast_prediction_interval(\n",
    "        self, ts: TSDataset, predictions: TSDataset, quantiles: Sequence[float], n_folds: int\n",
    "    ) -> TSDataset:\n",
    "        predicted_target = predictions[..., \"target\"]\n",
    "\n",
    "        lower_border = predicted_target.copy()\n",
    "        upper_border = predicted_target.copy()\n",
    "\n",
    "        fold_forecast = self.get_historical_forecasts(ts=ts, n_folds=n_folds, stride=self.stride)\n",
    "\n",
    "        for segment in ts.segments:\n",
    "            residuals = (\n",
    "                ts.loc[:, pd.IndexSlice[segment, \"target\"]] - fold_forecast.loc[:, pd.IndexSlice[segment, \"target\"]]\n",
    "            )\n",
    "            width = np.max(np.abs(residuals))\n",
    "\n",
    "            lower_border.loc[:, pd.IndexSlice[segment, \"target\"]] -= self.coverage * width / 2\n",
    "            upper_border.loc[:, pd.IndexSlice[segment, \"target\"]] += self.coverage * width / 2\n",
    "\n",
    "        upper_border.rename({\"target\": \"target_upper\"}, inplace=True, axis=1)\n",
    "        lower_border.rename({\"target\": \"target_lower\"}, inplace=True, axis=1)\n",
    "\n",
    "        predictions.add_prediction_intervals(prediction_intervals_df=pd.concat([lower_border, upper_border], axis=1))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = MaxAbsResidInterval(pipeline=pipeline)\n",
    "\n",
    "forecast = pipeline.forecast(prediction_interval=True, n_folds=5)\n",
    "\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_forecast(forecast, test_ts, train_ts, prediction_intervals=True, n_train_samples=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage, width = interval_metrics(test_ts=test_ts, forecast=forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining historical residuals for prediction intervals estimation can be simplified by using more efficient utility function `residuals_matrices`.\n",
    "This function accepts pipeline, data, parameters for backtest and estimates residuals for each segment on every fold.\n",
    "\n",
    "**Note** that `residuals_matrices` function returns 3 dimensional array with axes sizes `(num_folds, horizon, num_segments)`.\n",
    "\n",
    "Here we use this function to optimize proposed method. Consider `OptimizedMaxAbsResidInterval`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etna.experimental.prediction_intervals.utils import residuals_matrices\n",
    "\n",
    "\n",
    "class OptimizedMaxAbsResidInterval(BasePredictionIntervals):\n",
    "    def __init__(self, pipeline: BasePipeline, coverage: float = 0.95, stride: int = 1):\n",
    "        assert stride > 0\n",
    "        assert 0 < coverage <= 1\n",
    "\n",
    "        self.stride = stride\n",
    "        self.coverage = coverage\n",
    "        super().__init__(pipeline=pipeline)\n",
    "\n",
    "    def _forecast_prediction_interval(\n",
    "        self, ts: TSDataset, predictions: TSDataset, quantiles: Sequence[float], n_folds: int\n",
    "    ) -> TSDataset:\n",
    "        residuals = residuals_matrices(pipeline=self, ts=ts, n_folds=n_folds, stride=self.stride)\n",
    "\n",
    "        predicted_target = predictions[..., \"target\"]\n",
    "\n",
    "        width = np.max(np.abs(residuals), axis=(0, 1)).reshape(1, -1)\n",
    "\n",
    "        lower_border = predicted_target - self.coverage * width / 2\n",
    "        upper_border = predicted_target + self.coverage * width / 2\n",
    "\n",
    "        upper_border.rename({\"target\": \"target_upper\"}, inplace=True, axis=1)\n",
    "        lower_border.rename({\"target\": \"target_lower\"}, inplace=True, axis=1)\n",
    "\n",
    "        predictions.add_prediction_intervals(prediction_intervals_df=pd.concat([lower_border, upper_border], axis=1))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = OptimizedMaxAbsResidInterval(pipeline=pipeline)\n",
    "\n",
    "forecast = pipeline.forecast(prediction_interval=True, n_folds=3)\n",
    "\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_forecast(forecast, test_ts, train_ts, prediction_intervals=True, n_train_samples=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage, width = interval_metrics(test_ts=test_ts, forecast=forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
